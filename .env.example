# ╔══════════════════════════════════════════════════════════════════╗
# ║  RAG Chat — Environment Configuration                          ║
# ║  Copy to .env and fill in your values.                         ║
# ╚══════════════════════════════════════════════════════════════════╝

# ── LLM Provider ──────────────────────────────────────────────────
# Supported: cerebras, openai, anthropic
LLM_PROVIDER=cerebras
LLM_API_KEY=your-api-key-here
LLM_MODEL=                          # Empty = provider default
# LLM_BASE_URL=                     # Optional: custom endpoint (vLLM, Azure, etc.)

# ── Database (PostgreSQL + pgvector) ──────────────────────────────
# Option A: full connection string (takes priority)
# DATABASE_URL=postgresql://root:password@localhost:55432/chatapp

# Option B: individual vars
POSTGRES_HOST=localhost
POSTGRES_PORT=55432
POSTGRES_DB=chatapp
POSTGRES_USER=root
POSTGRES_PASSWORD=password

# ── Optional Redis Cache ──────────────────────────────────────────
# ENABLE_CACHE=false
# REDIS_URL=redis://localhost:6379/0

# ── Retrieval Tuning ──────────────────────────────────────────────
# RETRIEVAL_K=4                     # Documents per search
# QA_K=4                            # Prior Q&A matches
# TOPIC_CONTINUATION_THRESHOLD=0.35 # Min similarity for continuation
# CHUNK_SIZE=500                    # Characters per chunk
# CHUNK_OVERLAP=50                  # Overlap between chunks

# ── Knowledge Base ────────────────────────────────────────────────
# KNOWLEDGE_DIR=knowledge           # Directory with .txt/.md files
# FORCE_REINDEX=false               # Re-index on every startup

# ── Embeddings ────────────────────────────────────────────────────
# EMBEDDING_MODEL=BAAI/bge-base-en-v1.5  # Default (768-dim, ~440 MB)
# EMBEDDING_DIMENSION=768               # Must match model output size
# QUERY_INSTRUCTION=                     # Optional prefix for asymmetric retrieval
# Lighter: BAAI/bge-small-en-v1.5 (384-dim, ~133 MB) set EMBEDDING_DIMENSION=384

# ── Context Management ──────────────────────────────────────
# MAX_HISTORY_TOKENS=8000             # Token budget for conversation history
# ENABLE_HISTORY_SUMMARIZATION=true   # Summarize old turns (default: true)
# HISTORY_FETCH_LIMIT=100             # Max messages loaded per request

# ── Security ──────────────────────────────────────────────
# ALLOWED_ORIGINS=*                  # Restrict in production: comma-separated URLs
# DEFAULT_USER_ID=public             # Default user if none provided in request

# ── Server ────────────────────────────────────────────────────────
# HOST=0.0.0.0
# PORT=8000
# DEBUG_MODE=false                  # Show debug panels in UI
# STAGE_STREAMING=true              # Emit pipeline stage events
